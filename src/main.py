import os
import io
import csv
import json
import logging
import cv2
import base64
import uvicorn
import numpy as np
from PIL import Image
from datetime import datetime
from typing import List, Optional

from fastapi import FastAPI, File, UploadFile, Form, BackgroundTasks, HTTPException, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import face_recognition


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ ---
# –≠—Ç–∏ –º–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è –≤ Swagger (/docs)

class FaceLocation(BaseModel):
    top: int
    right: int
    bottom: int
    left: int

class FaceData(BaseModel):
    name: str
    location: FaceLocation
    encoding: List[float] = Field(..., description="–í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ª–∏—Ü–∞ –∏–∑ 128 —á–∏—Å–µ–ª.")

class RecognitionResponseData(BaseModel):
    faces_count: int
    faces: List[FaceData]
    processed_image_base64: str = Field(..., description="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–∞–º–∫–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Base64.")

class PersonInDB(BaseModel):
    id: int
    name: str
    added_date: str

class AddPersonResponseData(BaseModel):
    id: int
    name: str
    faces_found: int

class StatsData(BaseModel):
    total_persons: int
    last_added: Optional[dict] = None

class ApiResponse(BaseModel):
    success: bool
    message: str
    data: Optional[dict] = None


# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI
app = FastAPI(
    title="Face Recognition API",
    description="API –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü",
    version="1.0.0"
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å C# –∫–ª–∏–µ–Ω—Ç–æ–º
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —É–∫–∞–∂–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Middleware –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
@app.middleware("http")
async def log_requests(request: Request, call_next):
    logger.info(f"Request: {request.method} {request.url.path}")
    response = await call_next(request)
    logger.info(f"Response status: {response.status_code}")
    return response

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
CSV_FILE = "../persons_data.csv"
UPLOAD_DIR = "../uploads"
known_encodings = []
known_names = []
known_ids = []

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
os.makedirs(UPLOAD_DIR, exist_ok=True)

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class PersonResponse(BaseModel):
    id: int
    name: str
    added_date: str
    photo_path: str

class RecognitionResult(BaseModel):
    face_id: int
    name: str
    confidence: float
    location: dict

class ApiResponse(BaseModel):
    success: bool
    message: str
    data: Optional[dict] = None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
def init_csv():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CSV —Ñ–∞–π–ª–∞"""
    if not os.path.exists(CSV_FILE):
        with open(CSV_FILE, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['ID', '–ò–º—è', '–î–∞—Ç–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è', '–ü—É—Ç—å –∫ —Ñ–æ—Ç–æ', '–ö–æ–¥–∏—Ä–æ–≤–∫–∞ –ª–∏—Ü–∞'])

def load_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV"""
    global known_encodings, known_names, known_ids
    known_encodings = []
    known_names = []
    known_ids = []
    
    try:
        if os.path.exists(CSV_FILE):
            with open(CSV_FILE, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                next(reader)  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                
                for row in reader:
                    if len(row) >= 5:
                        person_id = int(row[0])
                        name = row[1]
                        encoding_str = row[4]
                        
                        if encoding_str:
                            encoding = np.array(json.loads(encoding_str))
                            known_encodings.append(encoding)
                            known_names.append(name)
                            known_ids.append(person_id)
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(known_names)} –∑–∞–ø–∏—Å–µ–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        else:
            logger.info("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞, —Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ñ–∞–π–ª")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def save_uploaded_file(upload_file: UploadFile) -> str:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{upload_file.filename}"
        file_path = os.path.join(UPLOAD_DIR, filename)
        
        content = upload_file.file.read()
        with open(file_path, "wb") as f:
            f.write(content)
        
        logger.info(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {file_path}")
        return file_path
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        raise

def image_to_base64(image_path: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode()

def base64_to_image(base64_string: str) -> np.ndarray:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è base64 –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
    img_data = base64.b64decode(base64_string)
    img = Image.open(io.BytesIO(img_data))
    return np.array(img)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
init_csv()
load_data()

# API Endpoints
@app.get("/")
async def root():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ API"""
    return {
        "status": "active",
        "service": "Face Recognition API",
        "version": "1.0.0",
        "endpoints": {
            "POST /api/person/add": "–î–æ–±–∞–≤–∏—Ç—å —á–µ–ª–æ–≤–µ–∫–∞",
            "POST /api/person/recognize": "–†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ª–∏—Ü–æ",
            "POST /api/video/recognize": "–†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ª–∏—Ü–∞ –Ω–∞ –≤–∏–¥–µ–æ",
            "GET /api/person/list": "–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ª—é–¥–µ–π",
            "GET /api/person/{id}": "–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–µ–ª–æ–≤–µ–∫–µ",
            "DELETE /api/person/{id}": "–£–¥–∞–ª–∏—Ç—å —á–µ–ª–æ–≤–µ–∫–∞",
            "GET /api/stats": "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã"
        }
    }

@app.post("/api/person/add",
          response_model=ApiResponse,
          tags=["–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π"],
          summary="–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –≤ –±–∞–∑—É")
async def add_person(
    name: str = Form(..., description="–ò–º—è –¥–æ–±–∞–≤–ª—è–µ–º–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞."),
    photo: UploadFile = File(..., description="–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è —á–µ–ª–æ–≤–µ–∫–∞ (–ª–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ä–æ—à–æ –≤–∏–¥–Ω–æ).")
):
    """
    –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    
    Parameters:
    - name: –ò–º—è —á–µ–ª–æ–≤–µ–∫–∞
    - photo: –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è (JPG, PNG)
    """
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        file_path = save_uploaded_file(photo)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        image = face_recognition.load_image_file(file_path)
        face_locations = face_recognition.face_locations(image)
        
        if len(face_locations) == 0:
            os.remove(file_path)  # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –µ—Å–ª–∏ –ª–∏—Ü–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "message": "–ù–∞ —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ª–∏—Ü",
                    "data": None
                }
            )
        
        if len(face_locations) > 1:
            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø–µ—Ä–≤—ã–º –ª–∏—Ü–æ–º
            print(f"–í–Ω–∏–º–∞–Ω–∏–µ: –Ω–∞–π–¥–µ–Ω–æ {len(face_locations)} –ª–∏—Ü, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–≤–æ–µ")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –ª–∏—Ü–∞
        face_encoding = face_recognition.face_encodings(image, face_locations)[0]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID
        person_id = len(known_ids) + 1
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –ø–∞–º—è—Ç—å
        known_encodings.append(face_encoding)
        known_names.append(name)
        known_ids.append(person_id)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        with open(CSV_FILE, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            encoding_str = json.dumps(face_encoding.tolist())
            writer.writerow([
                person_id,
                name,
                datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                file_path,
                encoding_str
            ])
        
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π —á–µ–ª–æ–≤–µ–∫: {name} (ID: {person_id})")
        
        return {
            "success": True,
            "message": f"–ß–µ–ª–æ–≤–µ–∫ '{name}' —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω",
            "data": {
                "id": person_id,
                "name": name,
                "faces_found": len(face_locations),
                "photo_path": file_path
            }
        }
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "message": f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}",
                "data": None
            }
        )
 
@app.post("/api/person/recognize",
          response_model=ApiResponse,
          tags=["–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ"],
          summary="–†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ª–∏—Ü–∞ –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏")
async def recognize_person(photo: UploadFile = File(..., description="–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.")):
    """
    –†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –ª–∏—Ü–∞, —Ä–∏—Å—É–µ—Ç –Ω–∞ —Ñ–æ—Ç–æ —Ä–∞–º–∫–∏ –∏ –∏–º–µ–Ω–∞,
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ª–∏—Ü–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Base64.
    """
    try:
        # –ß–∏—Ç–∞–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç—å –∫–∞–∫ –º–∞—Å—Å–∏–≤ –±–∞–π—Ç
        image_bytes = await photo.read()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –±–∞–π—Ç—ã –≤ –º–∞—Å—Å–∏–≤ NumPy, –∞ –∑–∞—Ç–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç OpenCV (BGR)
        np_array = np.frombuffer(image_bytes, np.uint8)
        image_bgr = cv2.imdecode(np_array, cv2.IMREAD_COLOR)
        
        # –î–ª—è face_recognition –Ω—É–∂–µ–Ω —Ñ–æ—Ä–º–∞—Ç RGB, –ø–æ—ç—Ç–æ–º—É –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ª–∏—Ü–∞ –∏ –∏—Ö –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        face_locations = face_recognition.face_locations(image_rgb)
        face_encodings = face_recognition.face_encodings(image_rgb, face_locations)
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(face_locations)} –ª–∏—Ü –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.")

        recognition_results = []
        
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É –Ω–∞–π–¥–µ–Ω–Ω–æ–º—É –ª–∏—Ü—É
        for i, (top, right, bottom, left) in enumerate(face_locations):
            face_encoding = face_encodings[i]
            
            name = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π"
            color = (0, 0, 255) # –ö—Ä–∞—Å–Ω—ã–π —Ü–≤–µ—Ç –¥–ª—è —Ä–∞–º–∫–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ
            
            if known_encodings:
                matches = face_recognition.compare_faces(known_encodings, face_encoding)
                face_distances = face_recognition.face_distance(known_encodings, face_encoding)
                
                if True in matches:
                    best_match_index = np.argmin(face_distances)
                    if matches[best_match_index]:
                        name = known_names[best_match_index]
                        color = (0, 255, 0) # –ó–µ–ª–µ–Ω—ã–π —Ü–≤–µ—Ç –¥–ª—è —Ä–∞–º–∫–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ

            # --- –†–∏—Å–æ–≤–∞–Ω–∏–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (–≤ —Ñ–æ—Ä–º–∞—Ç–µ BGR) ---
            cv2.rectangle(image_bgr, (left, top), (right, bottom), color, 2)
            cv2.rectangle(image_bgr, (left, bottom - 35), (right, bottom), color, cv2.FILLED)
            font = cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(image_bgr, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)

            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —ç—Ç–æ–≥–æ –ª–∏—Ü–∞
            recognition_results.append({
                "name": name, 
                "location": {"top": top, "right": right, "bottom": bottom, "left": left},
                "encoding": face_encoding.tolist()  # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä –≤ –æ—Ç–≤–µ—Ç
            })

        # --- –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Base64 ---
        _, buffer = cv2.imencode('.jpg', image_bgr)
        processed_image_base64 = base64.b64encode(buffer).decode('utf-8')

        return {
            "success": True,
            "message": f"–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.",
            "data": {
                "faces_count": len(recognition_results),
                "faces": recognition_results,
                "processed_image_base64": processed_image_base64
            }
        }

    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ /api/person/recognize: {e}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={"success": False, "message": f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}"}
        )

@app.get("/api/person/list",
         response_model=ApiResponse,
         tags=["–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π"],
         summary="–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ª—é–¥–µ–π –≤ –±–∞–∑–µ")
async def list_persons():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ª—é–¥–µ–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        persons = []
        
        if os.path.exists(CSV_FILE):
            with open(CSV_FILE, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                next(reader)  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                
                for row in reader:
                    if len(row) >= 4:
                        persons.append({
                            "id": int(row[0]),
                            "name": row[1],
                            "added_date": row[2],
                            "photo_path": row[3]
                        })
        
        return {
            "success": True,
            "message": f"–ù–∞–π–¥–µ–Ω–æ {len(persons)} —á–µ–ª–æ–≤–µ–∫",
            "data": {
                "count": len(persons),
                "persons": persons
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "message": f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}",
                "data": None
            }
        )

@app.get("/api/person/{person_id}",
         response_model=ApiResponse,
         tags=["–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π"],
         summary="–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —á–µ–ª–æ–≤–µ–∫–µ")
async def get_person(person_id: int):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —á–µ–ª–æ–≤–µ–∫–µ"""
    try:
        with open(CSV_FILE, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            next(reader)
            
            for row in reader:
                if len(row) >= 4 and int(row[0]) == person_id:
                    return JSONResponse(content={
                        "success": True,
                        "message": "–ß–µ–ª–æ–≤–µ–∫ –Ω–∞–π–¥–µ–Ω",
                        "data": {
                            "id": int(row[0]),
                            "name": row[1],
                            "added_date": row[2],
                            "photo_path": row[3],
                            "photo_base64": image_to_base64(row[3]) if os.path.exists(row[3]) else None
                        }
                    })
        
        raise HTTPException(status_code=404, detail="–ß–µ–ª–æ–≤–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/person/{person_id}",
            response_model=ApiResponse,
            tags=["–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π"],
            summary="–£–¥–∞–ª–∏—Ç—å —á–µ–ª–æ–≤–µ–∫–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
async def delete_person(person_id: int):
    """–£–¥–∞–ª–∏—Ç—å —á–µ–ª–æ–≤–µ–∫–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        rows = []
        deleted = False
        deleted_name = ""
        
        with open(CSV_FILE, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            rows.append(next(reader))  # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            
            for row in reader:
                if len(row) >= 5 and int(row[0]) != person_id:
                    rows.append(row)
                elif int(row[0]) == person_id:
                    deleted = True
                    deleted_name = row[1]
                    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª —Ñ–æ—Ç–æ –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                    if os.path.exists(row[3]):
                        os.remove(row[3])
        
        if not deleted:
            return JSONResponse(
                status_code=404,
                content={
                    "success": False,
                    "message": "–ß–µ–ª–æ–≤–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω",
                    "data": None
                }
            )
        
        # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
        with open(CSV_FILE, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerows(rows)
        
        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        load_data()
        
        return {
            "success": True,
            "message": f"–ß–µ–ª–æ–≤–µ–∫ '{deleted_name}' —É–¥–∞–ª–µ–Ω",
            "data": {
                "id": person_id,
                "name": deleted_name
            }
        }
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "message": f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}",
                "data": None
            }
        )

@app.get("/api/stats",
         response_model=ApiResponse,
         tags=["–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"],
         summary="–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
async def get_stats():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã"""
    try:
        total_persons = len(known_names)
        
        # –ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ
        last_added = None
        if os.path.exists(CSV_FILE):
            with open(CSV_FILE, 'r', encoding='utf-8') as f:
                reader = list(csv.reader(f))
                if len(reader) > 1:
                    last_row = reader[-1]
                    if len(last_row) >= 3:
                        last_added = {
                            "name": last_row[1],
                            "date": last_row[2]
                        }
        
        return {
            "success": True,
            "message": "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∞",
            "data": {
                "total_persons": total_persons,
                "total_photos": total_persons,
                "last_added": last_added,
                "storage_path": UPLOAD_DIR
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "message": f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}",
                "data": None
            }
        )

@app.post("/api/person/recognize-base64",
          response_model=ApiResponse,
          tags=["–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ"],
          summary="–†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ª–∏—Ü–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ base64")
async def recognize_person_base64(image_base64: str = Form(...)):
    """
    –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ª–∏—Ü–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ base64
    
    Parameters:
    - image_base64: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ base64
    """
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º base64 –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = base64_to_image(image_base64)
        
        # –ù–∞—Ö–æ–¥–∏–º –ª–∏—Ü–∞
        face_locations = face_recognition.face_locations(image)
        
        if len(face_locations) == 0:
            return JSONResponse(content={
                "success": True,
                "message": "–ù–∞ —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ª–∏—Ü",
                "data": {
                    "faces_count": 0,
                    "faces": []
                }
            })
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        face_encodings = face_recognition.face_encodings(image, face_locations)
        
        results = []
        
        for i, (face_encoding, face_location) in enumerate(zip(face_encodings, face_locations)):
            person_id = 0
            name = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π"
            confidence = 0.0
            
            if len(known_encodings) > 0:
                matches = face_recognition.compare_faces(known_encodings, face_encoding)
                face_distances = face_recognition.face_distance(known_encodings, face_encoding)
                
                if True in matches:
                    best_match_index = np.argmin(face_distances)
                    if matches[best_match_index]:
                        person_id = known_ids[best_match_index]
                        name = known_names[best_match_index]
                        confidence = float(1 - face_distances[best_match_index])
            
            top, right, bottom, left = face_location
            
            results.append({
                "face_id": i + 1,
                "person_id": person_id,
                "name": name,
                "confidence": round(confidence, 3),
                "location": {
                    "top": top,
                    "right": right,
                    "bottom": bottom,
                    "left": left
                }
            })
        
        return JSONResponse(content={
            "success": True,
            "message": f"–ù–∞–π–¥–µ–Ω–æ {len(results)} –ª–∏—Ü",
            "data": {
                "faces_count": len(results),
                "faces": results
            }
        })
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/video/recognize",
          response_model=ApiResponse,
          tags=["–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ"],
          summary="–†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ª–∏—Ü–∞ –Ω–∞ –≤–∏–¥–µ–æ")
async def recognize_video(
    video: UploadFile = File(..., description="–í–∏–¥–µ–æ—Ñ–∞–π–ª –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (MP4, AVI, MOV)"),
    frame_interval: int = Form(15, description="–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 15)")
):
    """
    –†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –ª–∏—Ü–∞ –Ω–∞ –≤–∏–¥–µ–æ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ª–∏—Ü–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ –∫–∞–¥—Ä—ã.
    """
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–¥–µ–æ—Ñ–∞–π–ª
        video_path = save_uploaded_file(video)
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ: {video_path}")
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
        video_capture = cv2.VideoCapture(video_path)
        
        if not video_capture.isOpened():
            os.remove(video_path)
            return JSONResponse(
                status_code=400,
                content={
                    "success": False,
                    "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª",
                    "data": None
                }
            )
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
        fps = video_capture.get(cv2.CAP_PROP_FPS)
        total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ù–ï–ò–ó–í–ï–°–¢–ù–´–• –ª–∏—Ü –≤ —ç—Ç–æ–º –≤–∏–¥–µ–æ
        temp_unknown_encodings = [] 
        person_appearances = {}
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        recognition_results = []
        key_frames = []
        processed_frames = 0
        frame_count = 0
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—è–≤–ª–µ–Ω–∏–π –ª—é–¥–µ–π
        person_appearances = {}
        
        logger.info(f"–í–∏–¥–µ–æ: {total_frames} –∫–∞–¥—Ä–æ–≤, {fps} FPS, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ {frame_interval} –∫–∞–¥—Ä–∞")
        
        while video_capture.isOpened():
            ret, frame = video_capture.read()
            
            if not ret:
                break
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä
            if frame_count % frame_interval == 0:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # –ù–∞—Ö–æ–¥–∏–º –ª–∏—Ü–∞
                face_locations = face_recognition.face_locations(rgb_frame)
                
                if face_locations:
                    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)
                    
                    # –ö–æ–ø–∏—Ä—É–µ–º –∫–∞–¥—Ä –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
                    annotated_frame = frame.copy()
                    frame_results = []
                    
                    for face_encoding, face_location in zip(face_encodings, face_locations):
                        name = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π"
                        confidence = 0.0
                        color = (0, 0, 255)  # –ö—Ä–∞—Å–Ω—ã–π –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö
                        
                        if known_encodings:
                            matches = face_recognition.compare_faces(known_encodings, face_encoding)
                            face_distances = face_recognition.face_distance(known_encodings, face_encoding)
                            
                            if True in matches:
                                best_match_index = np.argmin(face_distances)
                                if matches[best_match_index]:
                                    name = known_names[best_match_index]
                                    confidence = float(1 - face_distances[best_match_index])
                                    color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö
                        
                        if name == "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π":
                            if temp_unknown_encodings:
                                unknown_distances = face_recognition.face_distance(temp_unknown_encodings, face_encoding)
                                best_match_index = np.argmin(unknown_distances)
                                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø–æ—Ö–æ–∂–µ–µ –ª–∏—Ü–æ (–¥–∏—Å—Ç–∞–Ω—Ü–∏—è < 0.6), –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –µ–º—É —Ç–æ—Ç –∂–µ –Ω–æ–º–µ—Ä
                                if unknown_distances[best_match_index] < 0.6:
                                    name = f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π #{best_match_index + 1}" 
                                else:
                                    # –ò–Ω–∞—á–µ —ç—Ç–æ –Ω–æ–≤—ã–π –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ —Å–ø–∏—Å–æ–∫
                                    temp_unknown_encodings.append(face_encoding)
                                    name = f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π #{len(temp_unknown_encodings)}"
                            else:
                                # –≠—Ç–æ —Å–∞–º—ã–π –ø–µ—Ä–≤—ã–π –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤ –≤–∏–¥–µ–æ
                                temp_unknown_encodings.append(face_encoding)
                                name = f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π #1"
                        
                        # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É –∏ –∏–º—è
                        top, right, bottom, left = face_location
                        cv2.rectangle(annotated_frame, (left, top), (right, bottom), color, 2)
                        cv2.rectangle(annotated_frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)
                        cv2.putText(annotated_frame, name, (left + 6, bottom - 6), 
                                  cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        timestamp = frame_count / fps
                        frame_results.append({
                            "name": name,
                            "confidence": round(confidence, 3),
                            "timestamp": round(timestamp, 2),
                            "frame_number": frame_count
                        })
                        
                        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—è–≤–ª–µ–Ω–∏—è
                        if name not in person_appearances:
                            person_appearances[name] = {
                                "first_seen": timestamp,
                                "last_seen": timestamp,
                                "total_appearances": 0
                            }
                        person_appearances[name]["last_seen"] = timestamp
                        person_appearances[name]["total_appearances"] += 1
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª—é—á–µ–≤–æ–π –∫–∞–¥—Ä (–∫–∞–∂–¥—ã–π 5-–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–∞–¥—Ä —Å –ª–∏—Ü–∞–º–∏)
                    if processed_frames % 5 == 0 and len(key_frames) < 10:
                        _, buffer = cv2.imencode('.jpg', annotated_frame)
                        key_frame_base64 = base64.b64encode(buffer).decode('utf-8')
                        key_frames.append({
                            "frame_number": frame_count,
                            "timestamp": round(frame_count / fps, 2),
                            "faces_count": len(face_locations),
                            "image_base64": key_frame_base64
                        })
                    
                    recognition_results.extend(frame_results)
                    processed_frames += 1
                
                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 30 –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
                if processed_frames % 30 == 0:
                    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_frames} –∫–∞–¥—Ä–æ–≤ –∏–∑ {frame_count // frame_interval}")
            
            frame_count += 1
        
        video_capture.release()
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –≤–∏–¥–µ–æ—Ñ–∞–π–ª
        os.remove(video_path)
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ù–∞–π–¥–µ–Ω–æ {len(person_appearances)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏—Ü")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        summary = {
            "total_frames": total_frames,
            "processed_frames": frame_count // frame_interval if frame_interval > 0 else 0,
            "fps": round(fps, 2),
            "duration_seconds": round(total_frames / fps, 2) if fps > 0 else 0,
            "unique_persons": len(person_appearances),
            "person_appearances": {
                name: {
                    "first_seen": round(data["first_seen"], 2),
                    "last_seen": round(data["last_seen"], 2),
                    "total_appearances": data["total_appearances"]
                }
                for name, data in person_appearances.items()
            }
        }
        
        return {
            "success": True,
            "message": f"–í–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ. –ù–∞–π–¥–µ–Ω–æ {len(person_appearances)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏—Ü",
            "data": {
                "summary": summary,
                "key_frames": key_frames,
                "total_detections": len(recognition_results),
                "detections": recognition_results[:100]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {e}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "message": f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}",
                "data": None
            }
        )

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ Face Recognition API...")
    
    uvicorn.run(
        "main:app",  # –ü—É—Ç—å –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å—Ç—Ä–æ–∫–∏
        host="0.0.0.0",
        port=8000,
        reload=False,
        reload_dirs=["src"] # –°–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
    )